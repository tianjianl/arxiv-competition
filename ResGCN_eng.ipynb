{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Academic Papers Classification Contest\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Graph neural networks(GNNs) is a variant of neural network specialized in dealing with non-euclidean structured data. It is widely applied in recommender systems, financial risk control and biology computations. There are three types of Graph Neural Network problems: node classification, connectivity prediction and graph classification.\n",
    "\n",
    "The ogbn-arxiv dataset consists of many academic papers as nodes, with references as edges. Each paper is represented by a 100 dimensional vector. Our task is to infer their class based on their representations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Requirements \n",
    "This notebook is based on PaddlePaddle 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Structure of the Code\n",
    "\n",
    "1) Read the ogbn-arxiv files, Including the graph and node representations\n",
    "\n",
    "2) Construct the graph neural network\n",
    "\n",
    "3) Start Training\n",
    "\n",
    "4) Perform the final prediction and generate the submission file\n",
    "\n",
    "5) Using Label Propagation to further improve the accuracy of the sumbimission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "\u001b[31mERROR: parl 1.4.1 has requirement pyzmq==18.1.1, but you'll have pyzmq 22.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: paddlefsl 1.0.0 has requirement numpy~=1.19.2, but you'll have numpy 1.21.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: paddlefsl 1.0.0 has requirement pillow==8.2.0, but you'll have pillow 7.1.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: paddlefsl 1.0.0 has requirement requests~=2.24.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: blackhole 1.0.1 has requirement numpy<=1.19.5, but you'll have numpy 1.21.5 which is incompatible.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pgl-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/Cython already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pyximport already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/cython.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/Cython-0.29.26.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/easydict already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pgl already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/easydict-1.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy-1.21.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install pgl easydict -q -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pgl\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "\n",
    "config = {\n",
    "    \"model_name\": \"GCN\",\n",
    "    \"num_class\": 35,\n",
    "    \"num_layers\": 8,\n",
    "    \"dropout\": 0.3,\n",
    "    \"hidden_size\": 256,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"edge_dropout\": 0.00\n",
    "}\n",
    "\n",
    "config = edict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Loading \n",
    "\n",
    "In this cell block we read the dataset, including the graph and features, as well as the training/validation/testing set data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Dataset = namedtuple(\"Dataset\", \n",
    "               [\"graph\", \"num_classes\", \"train_index\",\n",
    "                \"train_label\", \"valid_index\", \"valid_label\", \"test_index\", \"node_feat\", \"edges\", \"node_label\"])\n",
    "\n",
    "def load_edges(num_nodes, self_loop=True, add_inverse_edge=True):\n",
    "    # read edges\n",
    "    edges = pd.read_csv(\"work/edges.csv\", header=None, names=[\"src\", \"dst\"]).values\n",
    "\n",
    "    if add_inverse_edge:\n",
    "        edges = np.vstack([edges, edges[:, ::-1]])\n",
    "\n",
    "    if self_loop:\n",
    "        src = np.arange(0, num_nodes)\n",
    "        dst = np.arange(0, num_nodes)\n",
    "        self_loop = np.vstack([src, dst]).T\n",
    "        edges = np.vstack([edges, self_loop])\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def load():\n",
    "    # read edges and features\n",
    "    node_feat = np.load(\"work/feat.npy\")\n",
    "    num_nodes = node_feat.shape[0]\n",
    "    edges = load_edges(num_nodes=num_nodes, self_loop=True, add_inverse_edge=True)\n",
    "    graph = pgl.graph.Graph(num_nodes=num_nodes, edges=edges, node_feat={\"feat\": node_feat})\n",
    "    \n",
    "    df = pd.read_csv(\"work/train.csv\")\n",
    "    node_index = df[\"nid\"].values\n",
    "    node_label = df[\"label\"].values\n",
    "    train_part = int(len(node_index) * 0.8)\n",
    "    train_index = node_index[:train_part]\n",
    "    train_label = node_label[:train_part]\n",
    "    valid_index = node_index[train_part:]\n",
    "    valid_label = node_label[train_part:]\n",
    "    test_index = pd.read_csv(\"work/test.csv\")[\"nid\"].values\n",
    "    dataset = Dataset(graph=graph, \n",
    "                    train_label=train_label,\n",
    "                    train_index=train_index,\n",
    "                    valid_index=valid_index,\n",
    "                    valid_label=valid_label,\n",
    "                    test_index=test_index, num_classes=35, node_feat = node_feat, edges = edges, node_label=node_label)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = load()\n",
    "\n",
    "train_index = dataset.train_index\n",
    "train_label = paddle.to_tensor(np.reshape(dataset.train_label, [-1 , 1]))\n",
    "train_index = paddle.to_tensor(np.expand_dims(train_index, -1))\n",
    "\n",
    "val_index = dataset.valid_index\n",
    "val_label = paddle.to_tensor(np.reshape(dataset.valid_label, [-1, 1]))\n",
    "val_index = paddle.to_tensor(np.expand_dims(val_index, -1))\n",
    "\n",
    "test_index = dataset.test_index\n",
    "test_index = paddle.to_tensor(np.expand_dims(test_index, -1))\n",
    "test_label = paddle.to_tensor(np.zeros((len(test_index), 1), dtype=\"int64\"))\n",
    "num_class = dataset.num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0109 17:23:01.197204   299 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0109 17:23:01.200810   299 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "import pgl\n",
    "from pgl.sampling import subgraph\n",
    "from pgl.graph import Graph\n",
    "import graphmodel_1\n",
    "from graphmodel_1 import Model\n",
    "from unimpmodel import UniMP\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    " #Using CPU\n",
    "#place = fluid.CPUPlace()\n",
    "# Using GPU\n",
    "place = fluid.CUDAPlace(0)\n",
    "model_name = config.get(\"model_name\", \"GCN\")\n",
    "if model_name == \"UniMP\":\n",
    "    model = UniMP(config)\n",
    "else:\n",
    "    model = Model(config)\n",
    "lr = 0.005\n",
    "#lr = paddle.optimizer.lr.ExponentialDecay(learning_rate=config.get(\"learning_rate\", 0.005), gamma=0.9, verbose=True)\n",
    "optim = paddle.optimizer.Adam(learning_rate = lr, parameters = model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Start Training\n",
    "Graph Neural Networks usually uses full batch training. However, GraphSAGE uses mini batch training. There are also algorithms that first partition the graph into subgraphs(Cluster-GCN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130644, 35]\n",
      "Epoch 0 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.01491422]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 1 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14850146])\n",
      "[130644, 35]\n",
      "Epoch 2 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14739802]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14850146])\n",
      "[130644, 35]\n",
      "Epoch 3 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14739802]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14850146])\n",
      "[130644, 35]\n",
      "Epoch 4 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14739802]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14850146])\n",
      "[130644, 35]\n",
      "Epoch 5 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14739802]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.17178045])\n",
      "[130644, 35]\n",
      "Epoch 6 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.16779384]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18715741])\n",
      "[130644, 35]\n",
      "Epoch 7 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18795829]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 8 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 9 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 10 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 11 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 12 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18509290])\n",
      "[130644, 35]\n",
      "Epoch 13 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18336655]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.15134904])\n",
      "[130644, 35]\n",
      "Epoch 14 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.15111768]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.15127786])\n",
      "[130644, 35]\n",
      "Epoch 15 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.15117107]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.16722432])\n",
      "[130644, 35]\n",
      "Epoch 16 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.16533780]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14857265])\n",
      "[130644, 35]\n",
      "Epoch 17 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14757599]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14850146])\n",
      "[130644, 35]\n",
      "Epoch 18 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14739802]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14850146])\n",
      "[130644, 35]\n",
      "Epoch 19 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.14739802]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 20 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18858120]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 21 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 22 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 23 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 24 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 25 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 26 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 27 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18843882])\n",
      "[130644, 35]\n",
      "Epoch 28 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18879476]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18801168])\n",
      "[130644, 35]\n",
      "Epoch 29 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18863459]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 30 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 31 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18859899]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18794048])\n",
      "[130644, 35]\n",
      "Epoch 32 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18865238]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18858120])\n",
      "[130644, 35]\n",
      "Epoch 33 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18929309]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18943547])\n",
      "[130644, 35]\n",
      "Epoch 34 Train Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18989819]) Valid Acc Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [0.18907952])\n",
      "[130644, 35]\n",
      "Epoch 35 Train Acc "
     ]
    }
   ],
   "source": [
    "epoch = 250\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "edges = dataset.edges\n",
    "graph = dataset.graph\n",
    "graph.tensor()\n",
    "for epoch in range(epoch):\n",
    "    # Full Batch Training\n",
    "    # input shape = [N, Cin]\n",
    "    # output shape [N, Co]\n",
    "\n",
    "    #pgl.sampling.subgraph(graph, nodes, eid=None, edges=None, with_node_feat=True, with_edge_feat=True)\n",
    "    #g = subgraph(graph=graph, nodes=train_index, edges=edges)\n",
    "    #g.tensor()\n",
    "    \n",
    "    pred = model(graph, graph.node_feat[\"feat\"])\n",
    "    print(pred.shape)\n",
    "    pred = paddle.gather(pred, train_index)\n",
    "    loss = criterion(pred, train_label)\n",
    "    loss.backward()\n",
    "    acc = paddle.metric.accuracy(input=pred, label=train_label, k=1)\n",
    "    \n",
    "    optim.step()\n",
    "    optim.clear_grad()\n",
    "    \n",
    "    #optim.minimize(loss)\n",
    "    #optim.clear_grad()\n",
    "    #if(epoch % 50 == 0):\n",
    "    #    lr.step()\n",
    "    \n",
    "    # Full Batch Validation\n",
    "    #g = subgraph(graph=graph, nodes=val_index, edges=edges)\n",
    "    #g.tensor()\n",
    "    val_pred = model(graph, graph.node_feat[\"feat\"])\n",
    "    val_pred = paddle.gather(val_pred, val_index)\n",
    "    val_acc = paddle.metric.accuracy(input=val_pred, label=val_label, k=1)\n",
    "    print(\"Epoch\", epoch, \"Train Acc\", acc, \"Valid Acc\", val_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Saving the model \n",
    "We use the PaddlePaddle API to save the model parameters for further correcting and smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred = model(graph, graph.node_feat[\"feat\"])\n",
    "test_pred = paddle.gather(test_pred, test_index)\n",
    "test_pred = paddle.argmax(test_pred, axis=1)\n",
    "test_index = np.array(test_index)\n",
    "test_pred = np.array(test_pred)\n",
    "submission = pd.DataFrame(data={\n",
    "                            \"nid\": test_index.reshape(-1),\n",
    "                            \"label\": test_pred.reshape(-1)\n",
    "                        })\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "#saving the state dict for smoothing final results \n",
    "paddle.save(model.state_dict(), \"model_state_dict\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Correct and Smooth\n",
    "Using Label Propagation to smooth the predicted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from correctandsmooth import LayerPropagation, CorrectAndSmooth\n",
    "\n",
    "model_state_dict = paddle.load('model_state_dict')\n",
    "model.load_dict(model_state_dict)\n",
    "y_pred = model(graph, graph.node_feat['feat']) \n",
    "\n",
    "y_soft = nn.functional.softmax(y_pred)\n",
    "\n",
    "cas = CorrectAndSmooth(50, 0.979, 'DAD', 100, 0.5, 'DAD', 20.)\n",
    "\n",
    "mask_idx = paddle.concat([train_index, val_index])\n",
    "node_label = paddle.to_tensor(np.reshape(dataset.node_label, [-1 , 1]))\n",
    "\n",
    "mask_label = paddle.gather(node_label, mask_idx)\n",
    "mask_label = paddle.nn.functional.one_hot(mask_label, num_classes=35)\n",
    "y_soft = cas.smooth(graph, y_soft, mask_label, mask_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generating Submission Files\n",
    "We have arrived at our last step! Use pandas to save the file to an csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = paddle.argmax(y_soft, axis=-1, keepdim=True)\n",
    "test_index = paddle.to_tensor(test_index)\n",
    "pred = paddle.gather(pred, test_index)\n",
    "test_index = np.array(test_index)\n",
    "pred = np.array(pred)\n",
    "\n",
    "test_index = np.array(test_index)\n",
    "pred = np.array(pred)\n",
    "submission = pd.DataFrame(data={\n",
    "                            \"nid\": test_index.reshape(-1),\n",
    "                            \"label\": pred.reshape(-1)\n",
    "                        })\n",
    "submission.to_csv(\"submission_cs.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
